<!DOCTYPE html>
<html lang="pt-BR">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Ethics Guide</title>
    <link rel="stylesheet" href="./assets/css/reset.css" />
    <link rel="stylesheet" href="./assets/css/style.css" />
  </head>
  <body>
    <header class="header">
      <!-- Nav -->
      <nav class="nav">
        <a  href="index.html" class="nav__logo">RE4AI Ethical Guide</a>
        <ul class="menu">
          <li class="menu__item"><a href="index.html">Introduction</a></li>
          <li class="menu__item"><a href="game.html">Guide</a></li>
          <li class="menu__item"><a href="principles.html">Principles</a></li>
          <li class="menu__item"><a href="tools.html">Tools</a></li>
          <li class="menu__item"><a href="tradeoffs.html">Trade-offs</a></li>
          <li class="menu__item"><a href="about.html">About</a></li>
        </ul>
      </nav>
      <!-- Main Section -->
      <section class="principal">
        <div class="content__title">
          <h1 class="title">Ethics in AI</h1>
          <h3 class="subtitle">Guide for Artificial Intelligence Ethical Requirements Elicitation</h3>
          <a href="game.html" class="button__game">Start Guide</a>
        </div>
        <div>
          <picture>
            <img
              class="illustration"
              src="./assets/img/card-game.svg"
              alt="RE4AI Ethical Guide logo"
            />
          </picture>
        </div>
      </section>
    </header>
    <!-- Section Principles -->
    <main class="container main">
      <h2">Principles</h2>
          <p>The evolution of the emergence of software that makes use of AI techniques, mostly ML, amplifies the manifestations of accidents and the awareness of the associated ethical issues \cite{morley2021EthicsAsAService}. In general, ethics in AI has been addressed, in the literature, in its theoretical field, through ethical guidelines \cite{mittelstadt2019principles}. In the last three years, there has been a veritable proliferation of organisations publishing guidelines seeking to provide normative guides to AI ethics \cite{benjamins2020towards}, \cite{Fjeld2020principled}. As of November 2019, at least 84 of these initiatives have published reports describing ethical principles, values or other high-level abstract requirements for the development and deployment of AI \cite{mittelstadt2019principles}. Due to this high number of publications, sometimes the terms appear interchangeably in the papers, as in the \href{https://futureoflife.org/ai-principles/}{Asilomar AI Principles}, where they present principles composed of guidelines. We assume throughout this paper that the guidelines -- the guides -- contain the principles of AI ethics.
          </p>
          <p>Whilst the existence of guidelines and principles is necessary, little practical direction exists for developers -- those responsible for implementing ethics in AI-based systems -- to apply in real-world contexts, even more so with the demands for market deliverables \cite{mittelstadt2019principles}, where often the ethical considerations involved is a quality to be considered in software only after its deployment \cite{vakkuri2020eccola}. Furthermore, developers do not receive adequate training within development projects, nor during their education. There are no legal consequences for not implementing AI ethics, as the guidelines present in the literature, and proposed by organisations, are often non-binding laws, and the AI developer not being a formal profession. To clarify: ``Reports and guidance documents for AI ethics are examples of what is called policy instruments of a non-binding character or soft law''\cite{jobin2019global}. Thus, there is neither motivation nor punishment for developers in the area of AI ethics. In this sense, binding laws are paramount to effectively align public interests with practice in application development in the context of AI.
          </p>
          <p>\textbf{legally binding documents}, backed by legislation, provide the actors involved in the process with real binding responsibilities and rights. These types of documents are called binding or hard law. We will present the two most notorious binding laws. First, the European Union's (EU) General Data Protection Regulation -- \textit{General Data Protection Rule} (GDPR) \cite{leiGDPR} -- which came into force on 25 May 2018 and has been hugely influential in establishing safeguards for personal data protection in today's technological environment. Several countries outside the EU have adopted similar data protection rules, analogous to or inspired by GDPR, which is increasingly being recognised for its high standard of data protection, Brazil being one such nation. Aimed at empowering EU citizens to have control over their data and protect them from data and privacy breaches, the GDPR applies to all relevant actors within the EU and those who process, monitor or store EU citizens' data outside the EU \cite{stix2019survey}. Second, the General Law on Personal Data Protection (LGPD) \cite{leiLGPD} in Brazil, which came into force on 18 September 2020, with the sanction of Law 14.058/2020, originating from Provisional Measure (MP) 959/20. The LGPD defines ``rights of individuals in relation to their personal information and rules for those who collect and handle these records with the aim of protecting the fundamental rights of freedom and privacy and the free development of the personality of citizens."\cite{ebc2020LGPD}. An effort towards harmonisation between AI ethics guidelines (non-binding) and legislation (legally binding) is an important next step for the global community \cite{jobin2019global}
          </P>
          <p>AI ethics guidelines contain ethical principles, and each published guideline contains its own set of principles. In the literature, most studies focus on the conceptual part of AI ethics, and one of them is the compilation, presentation and evaluation of ethics guidelines and their principles. Several authors have used different methodologies to explore sets of documents and extract the most recurrent principles and their definitions, usually concluding that they are too general, have high level of abstraction and degree of difficulty in applying them in real contexts, besides there is an overlap between the principles.
          </p>
          <p>Ryan and Stahl \cite{Ryan2020ArtificialIE} conducted a rigorous study with a robust methodology that reviewed a set of guidelines and compiled the detailed guidance that is available, presenting a list of principles aimed at developers and users. To the best of our knowledge, this is the study that makes use of a methodology that encompasses the most guidelines and definitions -- as well as presenting a comprehensive taxonomy.
      </p>
      <p>We have included below the authors' full text removing citations for readability.
      </p>
      
      <h1>1. Transparency </h1>
Transparency has quickly become one of the most widely discussed principles within the AI ethics debate, with Floridi (2019) and the High-Level Expert Group on AI (2019) viewing it as a defining characteristic within the debate. Transparency can typically be understood in two ways: the transparency of the AI technology itself and the transparency of the AI organisations developing and using it. Throughout our analysis, transparency was regularly discussed directly, or in relation to processes required to ensure it, such as explainability, understandability and communication.

      <h2>1.2 Transparency </h2>
AI developers need to ensure transparency because it protects many other requirements – such as the fundamental human rights, privacy, dignity, autonomy and well-being (UNI Global Union, 2017). Organisations using AI should be transparent about their aim for using AI, benefits and harms and potential outcomes that may occur (IBM, 2017). AI developers should ensure transparency because it allows consumers to make informed choices about sharing their data and using AI (ADMA, 2013). 

1.3 Explainability. 
AI must be subject to active monitoring to ensure that they are producing accurate results (Algo.Rules, 2019). AI organisations should document how their AI makes certain decisions and be able to reproduce them for audits (SIIA, 2017). AI should be explainable to external algorithmic auditing bodies to ensure the technical and ethical functionality of their AI. If there is a tension between performance and explainability, this should be clearly identified (Cerna Collectif, 2018). 

      
    </main>
    <!-- Seção Footer -->
    <footer class="footer">
      
      <p><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img style="border-width: 0;" src="https://i.creativecommons.org/l/by/4.0/80x15.png" alt="Creative Commons License" /><br />
      </a><br />
          Unless otherwise stated, the contents are licensed under
        <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 &#8211; International</a>. 
        The authors are responsible for the choice and presentation of their texts on this site and for the opinions expressed. <a href="https://github.com/josesiqueira/RE4AIEthicalGuide/">Source</a>.</p>
    </footer>
  </body>
</html>
